# Computer Vision

There are multiple sub-problems in the class of Computer Vision

- Multi-Class classification
  
     - extension of the Binary Class Classification

- Multi Label Classification

- Object Localization/Detection

- Image Segmentation
  
     - Semantic Segmentation
  
     - Instance Segmentation

## Multi Class and Binary Class Classification

In binary class classification problem, we try to classify the input image as one of the 2 classes that we are trying to recognize. 

In this scenario we have 

- an image as the input, 

- a CNN model

- 1 class as the output with the probability score of the class

Similarly in multi-class classification problem, we have more than 2 classes to classify our input image. Here similar to binary class classification we have:

- an image as the input

- a CNN model

- 1 class as the output with the probability score of the class

In these scenarios the CNN model architecture is very straight forward:

- **Input:** We have an input layer which takes the image as input

- **Feature Extractor:** A collection of convolution layers that are interconnected for feature extraction

- **Classifier:** A set of dense layers on top of the convolution layers as a classifier

- **Output:** either a softmax function applied to multiple nodes or a sigmoid function applied to 1 node to determine the class that has the highest probability for the input and the probability score of the class.



## Multi Label Classification

It is quite different from Multi-Class classification. Here we try to detect all the classes that might be present in the input image. So the thing that is different from the previous problem here is that we provide probability for all the classes that are present in the input image. Only the classes which have a probability score more than a said threshold is then given as output.

The process here is:

- an image as input

- a threshold for class selection

- a CNN model

- probability scores for all the classes and selection of certain classes which cross the threshold value.

Here the model architecture also remains the same except the output layer:

- **Input:** We have an input layer which takes the image as input

- **Feature Extractor:** A collection of convolution layers that are interconnected for feature extraction

- **Classifier:** A set of dense layers on top of the convolution layers as a classifier

- **Output:** a sigmoid function applied to all the nodes to determine the class probability for all the classes for the input.



## Object Localization

This is an additional task on top of the **multi label** classification problem as stated above. Here we try to also provide a bounding box value for a box that tightly bounds all the classes that has been detected. Here we usually have multiple output and the loss function is usually a collection of 2 loss functions:

- 1 for classification accuracy

- 1 for bounding box accuracy

Here the model changes a lot. We need a model which can do both the tasks simultaneously as a result there are multiple architectures proposed for this task. Some being:

- Fast/Faster RCNN

- YOLO

Here usually model has the following properties:

- **Input:** 1 input image

- **Feature Extractor**: a collection of layers performing feature extraction

- **Classifier:** a set of layers performing the task of classifying various objects in the input image

- **Bounding Box Regressor:** a collection of layers performing the task to get an accurate bounding box for all the classifications

> Here the model has multiple output rather than 1 output compared to image classification task.



## Image Segmentation

In this task we try to get the exact borders of the objects, rather than just the bounding box. This is usually done pixel by pixel method i.e. each and every pixel is checked inside a bounding box that whether it belongs to the object or the background and then the pixels are selected. Later we try to put on a mask i.e. a translucent map on top of the object covering the whole object. 

The mask prediction can be done in 2 ways:

- **Semantic Segmentation:** where we try to identify all the objects in the image and then put the same mask on all the objects belonging to the same class and a different mask on the objects that belong to different classes.

- **Instance Segmentation:** similar to the semantic segmentation but here we also segment the different instances of the same class objects i.e. we put different masks around different objects even if they belong to the same class.


