# Image Segmentation Foundation

Image Segmentation model usually has 2 parts to it
- Encoder
- Decoder

The model tries to perform a simple task here that is to find the pixel-wise classification i.e. which class does each pixel belong to.

It works on the concept that the encoder is used to get a smaller multi dimensional representation of the input image which are then fed to the Decoder to upsample it back to the original resolution which then has the per pixel classification.

## Encoder

Encoders are usually the feature extractor layers taken from a classification model.

## Decoders

There are many decoders available. Most prominent forms is the Fully Convolution Layers
- FCN 32
- FCN 16
- FCN 8

The main component of the decoder is the `UpSampling layer` which inverses the process performed by the Pooling layers and Convolution layer to output a larger tensor compared to the input.

### Upsampling Layer

We can 2 ways to perform this operation
- Up-scaling the input i.e. UpSampling2D layer
- Transposed Convolution or DeConvolution i.e. Conv2DTranspose

### UpSampling2D

It can be of 2 types
- Nearest
- BiLinear


```python
x = UpSampling2D(
    size=(2,2),
    data_format=None,  #'channels_first' or 'channels_last' or None
    interpolation='nearest')(x)
)
```
```python
x = Conv2DTranspose(
    filter=32,
    kernel_size=(3,3)
)
```


### Decoder Architectures

#### FCN32

In FCN 32 the output which has been downsampled 2^5 times using 5 convolution/pooling layers are upsampled back to the original form using a 32 stride Upsampling layer. The main issue with this is that as 1 layer itself takes care of a 32 stide upsampling, it looses a lot of information that could be retreived if we did the upsampling in steps.

#### FCN16

Here, like FCN32 we also try to upsample the input but with a 16 stride upsampling layer used twice in place of one 32 stride upsampling layer used once. Here in place of upsampling only the output twice 16stride at a time, we do the following:
- Upsample the 5th convolution/pooling layer's output 16stride.
- Do a 1x1 convolution on the 4th convolution/pooling layer's output and add it to the above 16stride output(Both have the same dimension)
- Do a second 16stide upsampling the above output to get back the original resolution


### FCN8

Just like in FCN16 we use the 4th convolution/pooling layer's output, here we additionally use the 3rd convolution/pooling layer's output as well. This helps us to retain more information and get a better each pixel classification. Here we use a 8stride convolution three times to get the original input image resolution as the output.