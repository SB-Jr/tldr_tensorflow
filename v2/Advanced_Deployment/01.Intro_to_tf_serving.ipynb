{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow Serving\n",
    "\n",
    "Making tensorflow models available to others for use through API calls in productionproduction.\n",
    "\n",
    "**This is part of TFX i.e Tensorflow Extended**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Hello World\n",
    "\n",
    "For this we need to install certain things first:\n",
    "- tensorflow-model-server (from AUR/apt/etc)\n",
    "- tensorflow-serving-api (from pip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-18T15:10:01.584570Z",
     "iopub.status.busy": "2020-12-18T15:10:01.583922Z",
     "iopub.status.idle": "2020-12-18T15:10:01.593610Z",
     "shell.execute_reply": "2020-12-18T15:10:01.591048Z",
     "shell.execute_reply.started": "2020-12-18T15:10:01.584495Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a basic Model\n",
    "\n",
    "This is a simple model that calculate y=2x-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-18T15:08:14.906967Z",
     "iopub.status.busy": "2020-12-18T15:08:14.906790Z",
     "iopub.status.idle": "2020-12-18T15:08:16.802455Z",
     "shell.execute_reply": "2020-12-18T15:08:16.800244Z",
     "shell.execute_reply.started": "2020-12-18T15:08:14.906945Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished training the model\n"
     ]
    }
   ],
   "source": [
    "# basic training data\n",
    "xs = np.array([-1.0,  0.0, 1.0, 2.0, 3.0, 4.0], dtype=float)\n",
    "ys = np.array([-3.0, -1.0, 1.0, 3.0, 5.0, 7.0], dtype=float)\n",
    "\n",
    "# basic model\n",
    "model = tf.keras.Sequential([tf.keras.layers.Dense(units=1, input_shape=[1])])\n",
    "\n",
    "model.compile(optimizer='sgd', loss='mean_squared_error')\n",
    "\n",
    "history = model.fit(xs, ys, epochs=500, verbose=0)\n",
    "\n",
    "print(\"Finished training the model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-18T15:08:42.267792Z",
     "iopub.status.busy": "2020-12-18T15:08:42.267112Z",
     "iopub.status.idle": "2020-12-18T15:08:42.543087Z",
     "shell.execute_reply": "2020-12-18T15:08:42.541804Z",
     "shell.execute_reply.started": "2020-12-18T15:08:42.267713Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[18.985289]]\n"
     ]
    }
   ],
   "source": [
    "# testing the model\n",
    "print(model.predict([10.0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the model to be served\n",
    "\n",
    "Here we try to save the model and later this saved model will be served through HTTP request and responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-18T15:23:20.571864Z",
     "iopub.status.busy": "2020-12-18T15:23:20.571213Z",
     "iopub.status.idle": "2020-12-18T15:23:21.147112Z",
     "shell.execute_reply": "2020-12-18T15:23:21.144797Z",
     "shell.execute_reply.started": "2020-12-18T15:23:20.571786Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/sbjr/my_workspace/tldr_tensorflow/v2/Advanced_Deployment/saved_model/hello_world/1/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/sbjr/my_workspace/tldr_tensorflow/v2/Advanced_Deployment/saved_model/hello_world/1/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved....Here are the contents\n",
      "total 48\n",
      "drwxr-xr-x 2 sbjr sbjr  4096 Dec 18 20:53 assets\n",
      "-rw-r--r-- 1 sbjr sbjr 39828 Dec 18 20:53 saved_model.pb\n",
      "drwxr-xr-x 2 sbjr sbjr  4096 Dec 18 20:53 variables\n"
     ]
    }
   ],
   "source": [
    "model_dir = f'{os.getcwd()}/saved_model/hello_world/'\n",
    "model_version = 1\n",
    "model_export_path = os.path.join(model_dir, str(model_version))\n",
    "\n",
    "if os.path.isdir(model_export_path):\n",
    "    print('Model already exists...so replacing it with the latest')\n",
    "    !rm -r {model_export_path}\n",
    "    \n",
    "model.save(model_export_path, save_format='tf')\n",
    "\n",
    "print('Model saved....Here are the contents')\n",
    "!ls -l {model_export_path}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examining the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-18T15:23:35.102493Z",
     "iopub.status.busy": "2020-12-18T15:23:35.101784Z",
     "iopub.status.idle": "2020-12-18T15:23:37.466391Z",
     "shell.execute_reply": "2020-12-18T15:23:37.464155Z",
     "shell.execute_reply.started": "2020-12-18T15:23:35.102411Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-12-18 20:53:35.428855: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/usr/lib64/:/opt/cuda-10.1/extras/CUPTI/lib64:/opt/cuda-10.1/lib64/:/opt/cudnn-7.6.5/lib64:/usr/lib64/:/opt/cuda-10.1/extras/CUPTI/lib64:/opt/cuda-10.1/lib64/:/opt/cudnn-7.6.5/lib64\n",
      "2020-12-18 20:53:35.428886: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "\n",
      "MetaGraphDef with tag-set: 'serve' contains the following SignatureDefs:\n",
      "\n",
      "signature_def['__saved_model_init_op']:\n",
      "  The given SavedModel SignatureDef contains the following input(s):\n",
      "  The given SavedModel SignatureDef contains the following output(s):\n",
      "    outputs['__saved_model_init_op'] tensor_info:\n",
      "        dtype: DT_INVALID\n",
      "        shape: unknown_rank\n",
      "        name: NoOp\n",
      "  Method name is: \n",
      "\n",
      "signature_def['serving_default']:\n",
      "  The given SavedModel SignatureDef contains the following input(s):\n",
      "    inputs['dense_input'] tensor_info:\n",
      "        dtype: DT_FLOAT\n",
      "        shape: (-1, 1)\n",
      "        name: serving_default_dense_input:0\n",
      "  The given SavedModel SignatureDef contains the following output(s):\n",
      "    outputs['dense'] tensor_info:\n",
      "        dtype: DT_FLOAT\n",
      "        shape: (-1, 1)\n",
      "        name: StatefulPartitionedCall:0\n",
      "  Method name is: tensorflow/serving/predict\n",
      "\n",
      "Defined Functions:\n",
      "  Function Name: '__call__'\n",
      "    Option #1\n",
      "      Callable with:\n",
      "        Argument #1\n",
      "          inputs: TensorSpec(shape=(None, 1), dtype=tf.float32, name='inputs')\n",
      "        Argument #2\n",
      "          DType: bool\n",
      "          Value: False\n",
      "        Argument #3\n",
      "          DType: NoneType\n",
      "          Value: None\n",
      "    Option #2\n",
      "      Callable with:\n",
      "        Argument #1\n",
      "          dense_input: TensorSpec(shape=(None, 1), dtype=tf.float32, name='dense_input')\n",
      "        Argument #2\n",
      "          DType: bool\n",
      "          Value: False\n",
      "        Argument #3\n",
      "          DType: NoneType\n",
      "          Value: None\n",
      "    Option #3\n",
      "      Callable with:\n",
      "        Argument #1\n",
      "          dense_input: TensorSpec(shape=(None, 1), dtype=tf.float32, name='dense_input')\n",
      "        Argument #2\n",
      "          DType: bool\n",
      "          Value: True\n",
      "        Argument #3\n",
      "          DType: NoneType\n",
      "          Value: None\n",
      "    Option #4\n",
      "      Callable with:\n",
      "        Argument #1\n",
      "          inputs: TensorSpec(shape=(None, 1), dtype=tf.float32, name='inputs')\n",
      "        Argument #2\n",
      "          DType: bool\n",
      "          Value: True\n",
      "        Argument #3\n",
      "          DType: NoneType\n",
      "          Value: None\n",
      "\n",
      "  Function Name: '_default_save_signature'\n",
      "    Option #1\n",
      "      Callable with:\n",
      "        Argument #1\n",
      "          dense_input: TensorSpec(shape=(None, 1), dtype=tf.float32, name='dense_input')\n",
      "\n",
      "  Function Name: 'call_and_return_all_conditional_losses'\n",
      "    Option #1\n",
      "      Callable with:\n",
      "        Argument #1\n",
      "          inputs: TensorSpec(shape=(None, 1), dtype=tf.float32, name='inputs')\n",
      "        Argument #2\n",
      "          DType: bool\n",
      "          Value: True\n",
      "        Argument #3\n",
      "          DType: NoneType\n",
      "          Value: None\n",
      "    Option #2\n",
      "      Callable with:\n",
      "        Argument #1\n",
      "          inputs: TensorSpec(shape=(None, 1), dtype=tf.float32, name='inputs')\n",
      "        Argument #2\n",
      "          DType: bool\n",
      "          Value: False\n",
      "        Argument #3\n",
      "          DType: NoneType\n",
      "          Value: None\n",
      "    Option #3\n",
      "      Callable with:\n",
      "        Argument #1\n",
      "          dense_input: TensorSpec(shape=(None, 1), dtype=tf.float32, name='dense_input')\n",
      "        Argument #2\n",
      "          DType: bool\n",
      "          Value: True\n",
      "        Argument #3\n",
      "          DType: NoneType\n",
      "          Value: None\n",
      "    Option #4\n",
      "      Callable with:\n",
      "        Argument #1\n",
      "          dense_input: TensorSpec(shape=(None, 1), dtype=tf.float32, name='dense_input')\n",
      "        Argument #2\n",
      "          DType: bool\n",
      "          Value: False\n",
      "        Argument #3\n",
      "          DType: NoneType\n",
      "          Value: None\n"
     ]
    }
   ],
   "source": [
    "!saved_model_cli show --dir {model_export_path} --all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the Tensorflow Model Server\n",
    "\n",
    "Here we will need to use the `signature_definition` value that we recieved from the `saved_model_cli` tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-18T15:23:49.870459Z",
     "iopub.status.busy": "2020-12-18T15:23:49.869806Z",
     "iopub.status.idle": "2020-12-18T15:23:49.880097Z",
     "shell.execute_reply": "2020-12-18T15:23:49.877181Z",
     "shell.execute_reply.started": "2020-12-18T15:23:49.870382Z"
    }
   },
   "outputs": [],
   "source": [
    "os.environ['TF_MODEL_DIR']=model_export_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-18T15:23:50.839943Z",
     "iopub.status.busy": "2020-12-18T15:23:50.838968Z",
     "iopub.status.idle": "2020-12-18T15:23:50.855634Z",
     "shell.execute_reply": "2020-12-18T15:23:50.852984Z",
     "shell.execute_reply.started": "2020-12-18T15:23:50.839820Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/sbjr/my_workspace/tldr_tensorflow/v2/Advanced_Deployment/saved_model/hello_world/1'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.environ['TF_MODEL_DIR']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-18T15:24:46.837467Z",
     "iopub.status.busy": "2020-12-18T15:24:46.836345Z",
     "iopub.status.idle": "2020-12-18T15:24:47.011530Z",
     "shell.execute_reply": "2020-12-18T15:24:47.009080Z",
     "shell.execute_reply.started": "2020-12-18T15:24:46.837337Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow_model_server not found\n"
     ]
    }
   ],
   "source": [
    "!which tensorflow_model_server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-18T15:24:17.943781Z",
     "iopub.status.busy": "2020-12-18T15:24:17.943113Z",
     "iopub.status.idle": "2020-12-18T15:24:17.987349Z",
     "shell.execute_reply": "2020-12-18T15:24:17.984465Z",
     "shell.execute_reply.started": "2020-12-18T15:24:17.943705Z"
    }
   },
   "outputs": [],
   "source": [
    "%%bash --bg\n",
    "nohup tensorflow_model_server --rest_api_port=8505 --model_name=hello_world --model_base_path=\"${TF_MODEL_DIR}\" > server.log 2>&1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-18T15:24:19.002910Z",
     "iopub.status.busy": "2020-12-18T15:24:19.002165Z",
     "iopub.status.idle": "2020-12-18T15:24:19.167065Z",
     "shell.execute_reply": "2020-12-18T15:24:19.164769Z",
     "shell.execute_reply.started": "2020-12-18T15:24:19.002823Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nohup: failed to run command 'tensorflow_model_server': No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!tail server.log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create data for testing API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = np.array([[9.0], [10.0]])\n",
    "data = json.dumps({\"signature_name\": \"serving_default\", \"instances\": xs.tolist()})\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Send the Json Data to the API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {\"content-type\": \"application/json\"}\n",
    "json_response = requests.post('http://localhost:8501/v1/models/helloworld:predict', data=data, headers=headers)\n",
    "\n",
    "print(json_response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = json.loads(json_response.text)['predictions']\n",
    "print(predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
