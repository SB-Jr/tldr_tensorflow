{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-16T08:57:14.101151Z",
     "iopub.status.busy": "2020-11-16T08:57:14.100560Z",
     "iopub.status.idle": "2020-11-16T08:57:14.110229Z",
     "shell.execute_reply": "2020-11-16T08:57:14.107043Z",
     "shell.execute_reply.started": "2020-11-16T08:57:14.101081Z"
    }
   },
   "source": [
    "# TFRecords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we are using the TFDS, we download the dataset and the dataset is often stored in forms of shards, i.e. the dataset is split into multiple sets(i.e. test, train and validation) and then the sets are further divided into shards and each shard contain a collection of rows.\n",
    "\n",
    "These shards are stored in the disk in binary format and in the form of TFRecords. We can take 1 shard at a time and decode it so as to view the data thus giving us much granular control of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading TFRecords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can read the raw TFRecords data that stores binary and can extract information from it.\n",
    "\n",
    "For this we need the record_info information while downloading the data so that it can be later used to parse the TFRecord."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "    filename = 'some_sharded_tfrecord_file'\n",
    "    raw_dataset = tf.data.TFRecordDataset(filename)\n",
    "    \n",
    "    # generated from the record_info obtained while loading a dataset\n",
    "    feature_description = {\n",
    "        'image' : tf.io.FixedLenFeature([], dtype=tf.string),\n",
    "        'label' : tf.io.FixedLenFeature([], dtype=tf.int64)\n",
    "    }\n",
    "    \n",
    "    def parse_dataset(proto):\n",
    "        return tf.io.parse_single_example(proto, feature_description)\n",
    "    \n",
    "    parsed_dataset = raw_dataset.map(parse_dataset)\n",
    "    \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
