{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorBoard\n",
    "\n",
    "Tensorboard is the interface used to visualize the graph and other tools to understand, debug, and optimize the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-03T16:06:51.605334Z",
     "start_time": "2020-02-03T16:06:51.599030Z"
    }
   },
   "source": [
    "Eg: A TensorBoard example\n",
    "<img src='artifacts/tensorboard_main.png'/><br>\n",
    "\n",
    "Different panels in tensorboard:\n",
    "<ul>\n",
    "    <li>Scalars: Show different useful information during the model training</li>\n",
    "    <li>Graphs: Show the model</li>\n",
    "    <li>Histogram: Display weights with a histogram</li>\n",
    "    <li>Distribution: Display the distribution of the weight</li>\n",
    "    <li>Projector: Show Principal component analysis and T-SNE algorithm. The technique uses for dimensionality reduction</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see how tensorboard can be helpful. When we visualize the graph of the loss function we can see that in the 1st case the network is not learning properly and while in the 2nd case the network seems to learn properly.\n",
    "<img src='artifacts/tensordboard_loss_function.png'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-03T16:12:53.235434Z",
     "start_time": "2020-02-03T16:12:53.187230Z"
    }
   },
   "outputs": [],
   "source": [
    "# A sample networabsk\n",
    "import numpy as np\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-03T16:14:31.205243Z",
     "start_time": "2020-02-03T16:14:31.190756Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 5)\n",
      "(10000, 1)\n"
     ]
    }
   ],
   "source": [
    "# creating data setabs\n",
    "X_train = np.random.sample((10000,5))\n",
    "Y_train = np.random.sample((10000,1))\n",
    "print(X_train.shape)\n",
    "print(Y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use tensorboard we need to create a log directory and keep log of the session being run.Tensorboard uses this logs to show graphs and other information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-03T16:59:24.597071Z",
     "start_time": "2020-02-03T16:59:24.569681Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'logs/6_tensorboard/', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f1b7f7d2c90>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "feature_cols = [tf.feature_column.numeric_column('x', shape=X_train.shape[1:])]\n",
    "# using pre loaded DNN Regresor provided by tensorflow\n",
    "learning_rate = 0.01\n",
    "l1_regularization_strength = 0.001\n",
    "dnn_reg = tf.estimator.DNNRegressor(feature_columns=feature_cols,\n",
    "model_dir='logs/6_tensorboard/',\n",
    "hidden_units=[500,300],\n",
    "optimizer=tf.train.ProximalAdagradOptimizer(learning_rate = learning_rate, l1_regularization_strength=l1_regularization_strength))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-03T16:59:51.616071Z",
     "start_time": "2020-02-03T16:59:27.450267Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layer dnn is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from logs/6_tensorboard/model.ckpt-3000\n",
      "WARNING:tensorflow:From /home/sbjr/my_bin/anaconda3/envs/tf-gpu/lib/python3.7/site-packages/tensorflow_core/python/training/saver.py:1069: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file utilities to get mtimes.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 3000 into logs/6_tensorboard/model.ckpt.\n",
      "INFO:tensorflow:loss = 11.809757, step = 3000\n",
      "INFO:tensorflow:global_step/sec: 311.607\n",
      "INFO:tensorflow:loss = 10.739077, step = 3100 (0.322 sec)\n",
      "INFO:tensorflow:global_step/sec: 255.715\n",
      "INFO:tensorflow:loss = 9.761114, step = 3200 (0.392 sec)\n",
      "INFO:tensorflow:global_step/sec: 122.108\n",
      "INFO:tensorflow:loss = 10.189515, step = 3300 (0.825 sec)\n",
      "INFO:tensorflow:global_step/sec: 85.504\n",
      "INFO:tensorflow:loss = 11.377788, step = 3400 (1.167 sec)\n",
      "INFO:tensorflow:global_step/sec: 114.445\n",
      "INFO:tensorflow:loss = 10.427271, step = 3500 (0.877 sec)\n",
      "INFO:tensorflow:global_step/sec: 90.2137\n",
      "INFO:tensorflow:loss = 10.509532, step = 3600 (1.103 sec)\n",
      "INFO:tensorflow:global_step/sec: 88.1396\n",
      "INFO:tensorflow:loss = 11.745427, step = 3700 (1.135 sec)\n",
      "INFO:tensorflow:global_step/sec: 100.716\n",
      "INFO:tensorflow:loss = 11.440798, step = 3800 (0.991 sec)\n",
      "INFO:tensorflow:global_step/sec: 317.653\n",
      "INFO:tensorflow:loss = 10.224135, step = 3900 (0.315 sec)\n",
      "INFO:tensorflow:global_step/sec: 356.412\n",
      "INFO:tensorflow:loss = 10.077078, step = 4000 (0.280 sec)\n",
      "INFO:tensorflow:global_step/sec: 330.317\n",
      "INFO:tensorflow:loss = 8.983885, step = 4100 (0.303 sec)\n",
      "INFO:tensorflow:global_step/sec: 130.034\n",
      "INFO:tensorflow:loss = 9.271311, step = 4200 (0.776 sec)\n",
      "INFO:tensorflow:global_step/sec: 102.788\n",
      "INFO:tensorflow:loss = 9.12722, step = 4300 (0.973 sec)\n",
      "INFO:tensorflow:global_step/sec: 116.499\n",
      "INFO:tensorflow:loss = 11.060432, step = 4400 (0.853 sec)\n",
      "INFO:tensorflow:global_step/sec: 171.73\n",
      "INFO:tensorflow:loss = 10.616493, step = 4500 (0.581 sec)\n",
      "INFO:tensorflow:global_step/sec: 330.922\n",
      "INFO:tensorflow:loss = 10.938026, step = 4600 (0.303 sec)\n",
      "INFO:tensorflow:global_step/sec: 173.145\n",
      "INFO:tensorflow:loss = 10.4155245, step = 4700 (0.581 sec)\n",
      "INFO:tensorflow:global_step/sec: 109.766\n",
      "INFO:tensorflow:loss = 10.10328, step = 4800 (0.915 sec)\n",
      "INFO:tensorflow:global_step/sec: 122.87\n",
      "INFO:tensorflow:loss = 10.128406, step = 4900 (0.809 sec)\n",
      "INFO:tensorflow:global_step/sec: 166.387\n",
      "INFO:tensorflow:loss = 10.758753, step = 5000 (0.598 sec)\n",
      "INFO:tensorflow:global_step/sec: 281.734\n",
      "INFO:tensorflow:loss = 11.304422, step = 5100 (0.355 sec)\n",
      "INFO:tensorflow:global_step/sec: 187.75\n",
      "INFO:tensorflow:loss = 11.416622, step = 5200 (0.533 sec)\n",
      "INFO:tensorflow:global_step/sec: 94.8099\n",
      "INFO:tensorflow:loss = 8.716904, step = 5300 (1.064 sec)\n",
      "INFO:tensorflow:global_step/sec: 114.782\n",
      "INFO:tensorflow:loss = 10.082016, step = 5400 (0.865 sec)\n",
      "INFO:tensorflow:global_step/sec: 134.897\n",
      "INFO:tensorflow:loss = 11.609472, step = 5500 (0.740 sec)\n",
      "INFO:tensorflow:global_step/sec: 147.047\n",
      "INFO:tensorflow:loss = 10.772163, step = 5600 (0.678 sec)\n",
      "INFO:tensorflow:global_step/sec: 94.2632\n",
      "INFO:tensorflow:loss = 9.777569, step = 5700 (1.061 sec)\n",
      "INFO:tensorflow:global_step/sec: 99.2688\n",
      "INFO:tensorflow:loss = 10.191159, step = 5800 (1.014 sec)\n",
      "INFO:tensorflow:global_step/sec: 102\n",
      "INFO:tensorflow:loss = 11.390812, step = 5900 (0.974 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 6000 into logs/6_tensorboard/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 10.343982.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow_estimator.python.estimator.canned.dnn.DNNRegressor at 0x7f1b7f7d2c50>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Train the estimator\n",
    "train_input = tf.estimator.inputs.numpy_input_fn(x={'x':X_train},y=Y_train, shuffle = False, num_epochs=None)    \n",
    "dnn_reg.train(train_input, steps=3000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running Tensorboard\n",
    "\n",
    "use this in terminal\n",
    "tensorboard --logdir=path/to/logs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
