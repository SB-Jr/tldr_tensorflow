{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Estimators\" data-toc-modified-id=\"Estimators-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Estimators</a></span></li><li><span><a href=\"#Basic-Prediction-Metrics\" data-toc-modified-id=\"Basic-Prediction-Metrics-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Basic Prediction Metrics</a></span></li><li><span><a href=\"#EstimatorSpec\" data-toc-modified-id=\"EstimatorSpec-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>EstimatorSpec</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorFlow Estimators is a High-level TensorFlow API that greatly simplifies machine learning programming introduced in a white paper in 2017. The design goals can be summarized as automating repetitive and error-prone tasks, encapsulating best practices, and providing a ride from training to deployment.<br>\n",
    "“TensorFlow’s high-level machine learning API (tf.estimator) makes it easy to configure, train, and evaluate a variety of machine learning models”"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T08:50:29.604029Z",
     "start_time": "2020-03-22T08:50:29.600201Z"
    }
   },
   "source": [
    "An Estimator is any class derived from tf.estimator.Estimator. TensorFlow provides a collection of pre-made Estimators (for example LinearRegressor) to implement common Machine Learning algorithms. These pre-implemented models allow quickly creating new models as need by customizing them. Beyond those, you may write your own custom Estimators."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='artifacts/estimator2.png'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The user specifies the meat of their model in a model_fn, using conditionals to denote behaviour that differs between TRAIN, EVALUATE and PREDICT. They add also a set of input_fn to describe how to handle data, optionally specifying them separately for training, evaluation, and prediction.\n",
    "These functions are consumed by the tf.estimator.Estimator class to return an initialized estimator, upon which we can call .train, .eval, and .predict."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At a high level, the code will need to create a custom Estimator (tf.estimator.Estimator) will be:\n",
    "- A model function <b>model_fn</b> that is fed the features, labels and a few other parameters where your model code processes them and produces losses, metrics etc. <b>The model function defines model, loss, optimizer, and metrics. This function has to return a <a>tf.estimator.EstimatorSpec</a></b>\n",
    "- Two input functions for training and evaluation phase each -> `input_fn` to feed the Estimators that returns features and labels.\n",
    "- <b>An experiment object</b>: to run the estimator in a configured state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus the `model_fn` will consist of the model definition and will return the EstimatorSpec object based on whether it is in training phase or evaluation phase or prediction phase."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimator object will accept this model function and will be given a model directory to store the output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While training/evaluating/predicting using the model, we will have to provide a `input_fn`.This input_fn accepts the train/evaluation/prediction features and the labels(in case of training and evaluating case) and will return the features and labels corresponding to the features.<br><br>\n",
    "\n",
    "This input_fn will take the features and the labels as input and create a tf.data.Dataset object out it. Perform transformations on this object and then create an iterator of the dataset object. This iterator iterates over the dataset, returning 2 values:\n",
    "- feature\n",
    "- corresponding label\n",
    "\n",
    "<b>Note: In case of prediction, the input_fn returns only the dataset, i.e. it doesn't create an iterator on this dataset. It just performs transformation(if any) and returns the dataset(and thus only uses the x as input and not y)<b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Prediction Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The estimator class when used to evaluate a model it returns an object consisting of the following metrics:\n",
    "\n",
    "- accuracy: Percentage of correct number of classifications\n",
    "- accuracy_baseline: Accuracy baseline based on labels mean. This is the best the model could do by always predicting one class. (source)\n",
    "- AUC or Area Under the (ROC) Curve is quite complicated, but tells you something about the true/false positive rate. In short: the AUC is equal to the probability that a classifier will rank a randomly chosen positive instance higher than a randomly chosen negative one.\n",
    "- auc_precision_recall: Is the percentage of relevant intstances, among the retrieved instances, that have been retrieved over the total amount of relevant instances.\n",
    "- average_loss: You're usually minimizing some function, and this is likely the average value of that function given the current batches.\n",
    "- loss: The current value of the loss (as above). Either the sum of the losses, or the loss of the last batch.\n",
    "- global_step: Number of iterations.\n",
    "- label/mean and prediction/mean: Not really sure, but I suspect that if you have two classes then the label/mean is the mean of the value labels, whilst prediction/mean could be the value of the corresponding predictions. (two classes could give you a value between 0 and 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EstimatorSpec\n",
    "\n",
    "The object returned by the `model_fn` to the estimator is the EstimatorSpec object. It fully defines the model has to be run by the estimator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
