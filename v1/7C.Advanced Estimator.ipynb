{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Structre\" data-toc-modified-id=\"Structre-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Structre</a></span></li><li><span><a href=\"#Creating-the-Estimator\" data-toc-modified-id=\"Creating-the-Estimator-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Creating the Estimator</a></span></li><li><span><a href=\"#Dataset\" data-toc-modified-id=\"Dataset-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Dataset</a></span><ul class=\"toc-item\"><li><span><a href=\"#Explanation\" data-toc-modified-id=\"Explanation-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Explanation</a></span><ul class=\"toc-item\"><li><span><a href=\"#Extract\" data-toc-modified-id=\"Extract-3.1.1\"><span class=\"toc-item-num\">3.1.1&nbsp;&nbsp;</span>Extract</a></span></li><li><span><a href=\"#Transform\" data-toc-modified-id=\"Transform-3.1.2\"><span class=\"toc-item-num\">3.1.2&nbsp;&nbsp;</span>Transform</a></span></li><li><span><a href=\"#Load\" data-toc-modified-id=\"Load-3.1.3\"><span class=\"toc-item-num\">3.1.3&nbsp;&nbsp;</span>Load</a></span></li></ul></li></ul></li><li><span><a href=\"#Input_fn\" data-toc-modified-id=\"Input_fn-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Input_fn</a></span></li><li><span><a href=\"#Model_fn\" data-toc-modified-id=\"Model_fn-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Model_fn</a></span><ul class=\"toc-item\"><li><span><a href=\"#Predict-(“tf.estimator.ModeKeys.PREDICT”)\" data-toc-modified-id=\"Predict-(“tf.estimator.ModeKeys.PREDICT”)-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>Predict (“tf.estimator.ModeKeys.PREDICT”)</a></span></li><li><span><a href=\"#Train-(&quot;tf.estimator.ModeKeys.TRAIN&quot;)\" data-toc-modified-id=\"Train-(&quot;tf.estimator.ModeKeys.TRAIN&quot;)-5.2\"><span class=\"toc-item-num\">5.2&nbsp;&nbsp;</span>Train (\"tf.estimator.ModeKeys.TRAIN\")</a></span></li><li><span><a href=\"#Evaluate-(&quot;tf.estimator.ModeKeys.EVAL&quot;)\" data-toc-modified-id=\"Evaluate-(&quot;tf.estimator.ModeKeys.EVAL&quot;)-5.3\"><span class=\"toc-item-num\">5.3&nbsp;&nbsp;</span>Evaluate (\"tf.estimator.ModeKeys.EVAL\")</a></span></li></ul></li><li><span><a href=\"#Scaffolds-and-SessionRunHooks\" data-toc-modified-id=\"Scaffolds-and-SessionRunHooks-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Scaffolds and SessionRunHooks</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Structre</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we will follow this basic structure:\n",
    "\n",
    "<ol>\n",
    "    <li>Create Estimator\n",
    "        <ol>\n",
    "            <li>creating model_fn</li>\n",
    "        </ol>\n",
    "    </li>\n",
    "    <li>Data Loading</li>\n",
    "    <li>Defining Train, Evaluate and Prediction phases</li>\n",
    "    <li>Session and hooks</li>\n",
    "    <li>Prediction</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the Estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating an estimator is simple:\n",
    "<pre><code>classifier = tf.estimator.Estimator(model_dir=model_dir,\n",
    "                                          model_fn=model_fn,\n",
    "                                          params=params)</code></pre>\n",
    "In this call “model_dir” is the path to the folder where the Estimator should store and load checkpoints and event files. The “model_fn” parameter is a function that consumes the features, labels, mode and params "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset\n",
    "\n",
    "The Tensorflow Dataset class is designed as an E.T.L. process, which stands for Extract, Transform and Load.\n",
    "<img src = 'artifacts/etl.png'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre><code>\n",
    "with tf.name_scope(\"tf_record_reader\"):\n",
    "    # generate file list\n",
    "    files = tf.data.Dataset.list_files(glob_pattern, shuffle=training)\n",
    "\n",
    "    # parallel fetch tfrecords dataset using the file list in parallel\n",
    "    dataset = files.apply(tf.contrib.data.parallel_interleave(\n",
    "        lambda filename: tf.data.TFRecordDataset(filename), cycle_length=threads))\n",
    "\n",
    "    # shuffle and repeat examples for better randomness and allow training beyond one epoch\n",
    "    dataset = dataset.apply(tf.contrib.data.shuffle_and_repeat(32*self.batch_size))\n",
    "\n",
    "    # map the parse  function to each example individually in threads*2 parallel calls\n",
    "    dataset = dataset.map(map_func=lambda example: _parse_function(example, self.image_size, self.num_classes,training=training), num_parallel_calls=threads)\n",
    "\n",
    "    # batch the examples\n",
    "    dataset = dataset.batch(batch_size=self.batch_size)\n",
    "\n",
    "    #prefetch batch\n",
    "    dataset = dataset.prefetch(buffer_size=self.batch_size)\n",
    "\n",
    "    return dataset.make_one_shot_iterator()\n",
    "</code></pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explanation\n",
    "\n",
    "### Extract\n",
    "\n",
    "The first step in a Dataset input pipeline is to load the data from the tfrecords into memory. This starts with making a list of tfrecords available using a <b>glob pattern</b> e.g. “./Datasets/train-*.tfrecords” and the <b>list_files</b> function of the Dataset class.<br>\n",
    "\n",
    "The <b>parallel_interleave</b> function is applied to the list of files, which ensures parallel extraction of the data .<br>\n",
    "\n",
    "Finally a merged shuffle and repeat function is used to prefetch a certain number of examples from the tfrecords and shuffle them. The repeat ensures that there are always examples available by repeating from the start once the last example of every tfrecord is read.\n",
    "\n",
    "<pre><code>\n",
    "with tf.name_scope(\"tf_record_reader\"):\n",
    "    # generate file list\n",
    "    files = tf.data.Dataset.list_files(glob_pattern, shuffle=training)\n",
    "\n",
    "    # parallel fetch tfrecords dataset using the file list in parallel\n",
    "    dataset = files.apply(tf.contrib.data.parallel_interleave(\n",
    "        lambda filename: tf.data.TFRecordDataset(filename), cycle_length=threads))\n",
    "\n",
    "    # shuffle and repeat examples for better randomness and allow training beyond one epoch\n",
    "    dataset = dataset.apply(tf.contrib.data.shuffle_and_repeat(32*self.batch_size))\n",
    "</code></pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform\n",
    "\n",
    "Now that the data is available in memory the next step is to transform it, preferably into something that does not need any further processing in order to be fed to the neural network input.<br>\n",
    "A call to the dataset’s map function is required to do this as shown below, where <b>“map_func”</b> is the function applied to every individual example on the CPU and <b>“num_parallel_calls”</b> the number of parallel invocations of the “map_func” to use.\n",
    "    \n",
    "<pre><code>\n",
    "threads = multiprocessing.cpu_count()\n",
    "\n",
    " # map the parse  function to each example individually in threads*2 parallel calls\n",
    "    dataset = dataset.map(map_func=lambda example: _parse_function(example, self.image_size, self.num_classes,training=training), num_parallel_calls=threads)\n",
    "</code></pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load\n",
    "\n",
    "The final step of the ETL process is loading the batched examples onto the accelerator (GPU) ready for processing. In the Dataset class this is achieved by prefetching, which is done by calling the prefetch function of the dataset.\n",
    "\n",
    "<pre><code>\n",
    "dataset = dataset.prefetch(buffer_size=self.batch_size)\n",
    "</code></pre>\n",
    "\n",
    "Prefetching uncouples the producer (Dataset object on CPU) from the consumer (GPU), this allows them to run in parallel for increased throughput."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input_fn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-08T05:27:29.769507Z",
     "start_time": "2020-04-08T05:27:29.765145Z"
    }
   },
   "source": [
    "Once the whole E.T.L. process is fully defined and implemented, the “input_fn” can be created by initializing the iterator and grabbing the next example.\n",
    "<pre><code>\n",
    "input_fn = dataset.make_one_shot_iterator().get_next()\n",
    "</code></pre>\n",
    "This input function is used by the Estimator as an input for the model function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model_fn\n",
    "\n",
    "<img src='artifacts/estimator.jpeg'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model function the estimator invokes during training, evaluation and prediction, should accept the following arguments:\n",
    "\n",
    "<pre><code>\n",
    "def model_fn(features, labels, mode, params):\n",
    "</code></pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code-path of every mode has to return an <b>“EstimatorSpec”</b> with the required fields for that mode.\n",
    "\n",
    "## Predict (“tf.estimator.ModeKeys.PREDICT”)\n",
    "\n",
    "It has to return an “EstimatorSpec” that includes the predictions field:\n",
    "\n",
    "<pre><code>\n",
    "return tf.estimator.EstimatorSpec(mode, predictions=predictions)\n",
    "</code></pre>\n",
    "\n",
    "<b>In this mode the “EstimatorSpec” expects a dictionary of tensors which will be executed and the results of which will be made available as numpy values to python.</b><br>\n",
    "\n",
    "It is smart to define the prediction code-path first as it is the simplest, and since most of the code is used for training and evaluation as-well it can show problems early on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train (\"tf.estimator.ModeKeys.TRAIN\")\n",
    "\n",
    "It is necessary to create a so called <b>“train_op”</b>, this op is a tensor that when executed performs the back propagation to update the model. Simply put it is the minimize function of an optimizer such as the AdamOptimizer. The <b>“train_op”</b> and the <b>scalar loss</b> tensor are the minimum required arguments to create an “EstimatorSpec” for training. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate (\"tf.estimator.ModeKeys.EVAL\")\n",
    "\n",
    "The most important thing in order to perform an eval is the the metrics dictionary, this should be structured as a dictionary of tuples, where the first element of the tuple is a tensor containing the actual metric value and the second element is the tensor that updates the metric value. The update operation is necessary to ensure a reliable metric calculation over the whole validation set. Since it will often be impossible to evaluate the whole validation set in one batch, multiple batches have to be used. To prevent noise in the metric value due to per batch differences, the update operation is used to keep a running average (or gather all results) over all batches. This setup ensures the metric value is calculated over the whole validation set and not a single batch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scaffolds and SessionRunHooks\n",
    "\n",
    "<img src='artifacts/scaffolds_and_session_run_hooks.png' />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
