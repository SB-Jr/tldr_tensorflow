{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow Pipeline\n",
    "\n",
    "The pipeline will load the data in batch, or small chunk. Each batch will be pushed to the pipeline and be ready for the training. Building a pipeline is an excellent solution because it allows you to use parallel computing. It means Tensorflow will train the model across multiple CPUs. It fosters the computation and permits for training powerful neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Steps to create a pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-03T15:24:47.283087Z",
     "start_time": "2020-02-03T15:24:47.277384Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.90019516 0.42533469 0.78767511 0.88946094]\n",
      " [0.29206842 0.7553205  0.58801091 0.40242626]\n",
      " [0.84887678 0.52333101 0.94105812 0.10045303]]\n"
     ]
    }
   ],
   "source": [
    "#here we will use numpy to generate arbitary data\n",
    "import numpy as np\n",
    "\n",
    "x_input = np.random.sample((3,4)) #data dimension is 3x4\n",
    "print(x_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create placeholders\n",
    "\n",
    "create the place holders to hold the data while running the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-03T15:27:15.727865Z",
     "start_time": "2020-02-03T15:27:15.710154Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_eager_execution()\n",
    "\n",
    "x = tf.placeholder(tf.float32,name = 'x', shape = [3,4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the dataset\n",
    "\n",
    "We need to define the Dataset where we can populate the value of the placeholder x. We need to use the method `tf.data.Dataset.from_tensor_slices`<br>\n",
    "<b>from_tensor_slices</b>: This method accepts individual (or multiple) Numpy (or Tensors) objects. In case you are feeding multiple objects, pass them as tuple and make sure that all the objects have same size in zeroth dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-03T15:28:56.835389Z",
     "start_time": "2020-02-03T15:28:56.825824Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the pipeline\n",
    "\n",
    "We need to initialize the pipeline where the data will flow. We need to create an iterator with `make_initializable_iterator`. We name it iterator. Then we need to call this iterator to feed the next batch of data, `get_next`. We name this step get_next. Note that in our example, there is only one batch of data<br>\n",
    "\n",
    "Tensorflow has provided four types of iterators and each of them has a specific purpose and use-case behind it.\n",
    "\n",
    "Regardless of the type of iterator, get_next function of iterator is used to create an operation in your Tensorflow graph which when run over a session, returns the values from the fed Dataset of iterator. Also, iterator doesn’t keep track of how many elements are present in the Dataset. Hence, it is normal to keep running the iterator’s get_next operation till Tensorflow’s `tf.errors.OutOfRangeError` exception is occurred."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-03T16:00:51.868292Z",
     "start_time": "2020-02-03T16:00:51.844776Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"IteratorGetNext_2:0\", shape=(4,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "iterator = tf.data.make_initializable_iterator(dataset)\n",
    "get_next = iterator.get_next()\n",
    "print(get_next)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execute the Operation\n",
    "\n",
    "We initiate a session, and we run the operation iterator. We feed the feed_dict with the value generated by numpy. These two value will populate the placeholder x. Then we run get_next to print the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-03T15:58:59.357113Z",
     "start_time": "2020-02-03T15:58:59.289451Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9001952 0.4253347 0.7876751 0.8894609]\n",
      "[0.29206842 0.7553205  0.5880109  0.40242627]\n",
      "[0.8488768  0.523331   0.9410581  0.10045303]\n",
      "---Finished Execution---\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(iterator.initializer, feed_dict={x:x_input})\n",
    "    try:\n",
    "        while True:\n",
    "            print(sess.run(get_next))\n",
    "    except tf.errors.OutOfRangeError:\n",
    "        print('---Finished Execution---')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
